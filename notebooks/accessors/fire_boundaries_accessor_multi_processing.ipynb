{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59a5672",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance guards\n",
    "import os, warnings\n",
    "os.environ.setdefault(\"OMP_NUM_THREADS\", \"1\")\n",
    "os.environ.setdefault(\"MKL_NUM_THREADS\", \"1\")\n",
    "os.environ.setdefault(\"NUMEXPR_NUM_THREADS\", \"1\")\n",
    "warnings.filterwarnings(\"ignore\", message=\"Can't initialize NVML\")\n",
    "\n",
    "from pathlib import Path\n",
    "import re, uuid\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rasterio\n",
    "from rasterio.windows import Window\n",
    "from rasterio.features import rasterize\n",
    "from shapely.geometry import mapping\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import pyarrow.dataset as ds\n",
    "\n",
    "# ---------------- config ----------------\n",
    "DATA_ROOT = Path(\"../../Dataset\")\n",
    "DIST_ROOT = DATA_ROOT / \"AnnualDisturbance_1999_present\"\n",
    "EVENTS_ROOT = Path(\"../../Outputs\") / \"treatments\"\n",
    "OUT_ROOT = Path(\"../../Outputs\") / \"model_database\"\n",
    "FIRE_GDB = DATA_ROOT / \"S_USA.MTBS_BURN_AREA_BOUNDARY.gdb\"\n",
    "\n",
    "LOOKBACK_YEARS = 10\n",
    "BUFFER_METERS = 1609            # ~1 mile\n",
    "TILE_SIZE = 4096                # must match step 1 output\n",
    "WRITE_BUFFER_ROWS = 200_000     # rows per file before flushing\n",
    "# ---------------------------------------\n",
    "\n",
    "OUT_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ---------- reference grid ----------\n",
    "def find_reference_tif(dist_root: Path) -> Path:\n",
    "    cands = sorted(dist_root.rglob(\"Tif/*.tif\"))\n",
    "    if not cands:\n",
    "        raise FileNotFoundError(\"No disturbance GeoTIFFs found under Dataset/AnnualDisturbance_1999_present\")\n",
    "    return cands[0]\n",
    "\n",
    "def open_grid(ref_tif: Path):\n",
    "    return rasterio.open(ref_tif)  # caller closes\n",
    "\n",
    "# ---------- tiling helpers ----------\n",
    "def tiles_covering_bbox(r0, c0, r1, c1, tile_size):\n",
    "    ti0 = max(0, r0 // tile_size); tj0 = max(0, c0 // tile_size)\n",
    "    ti1 = r1 // tile_size;         tj1 = c1 // tile_size\n",
    "    for ti in range(ti0, ti1 + 1):\n",
    "        for tj in range(tj0, tj1 + 1):\n",
    "            yield (ti, tj)\n",
    "\n",
    "def window_from_tile(ti, tj, H, W, tile_size):\n",
    "    row_off = ti * tile_size\n",
    "    col_off = tj * tile_size\n",
    "    height  = min(tile_size, H - row_off)\n",
    "    width   = min(tile_size, W - col_off)\n",
    "    return Window(col_off=col_off, row_off=row_off, width=width, height=height)\n",
    "\n",
    "# ---------- events (step-1) lookup ----------\n",
    "def _encode_keys(rows: np.ndarray, cols: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Combine (row, col) into uint64 keys for fast membership.\"\"\"\n",
    "    return (rows.astype(np.uint64) << 32) | cols.astype(np.uint64)\n",
    "\n",
    "def load_event_keys_for_partition(events_root: Path, year: int, tile_i: int, tile_j: int) -> np.ndarray:\n",
    "    \"\"\"Return uint64 keys for pixels treated in given (year, tile_i, tile_j).\"\"\"\n",
    "    part_dir = events_root / f\"yr={year}\" / f\"tile_i={tile_i}\" / f\"tile_j={tile_j}\"\n",
    "    if not part_dir.exists():\n",
    "        return np.empty(0, dtype=np.uint64)\n",
    "    dset = ds.dataset(part_dir.as_posix(), format=\"parquet\")\n",
    "    tbl = dset.to_table(columns=[\"row\", \"col\"])\n",
    "    if tbl.num_rows == 0:\n",
    "        return np.empty(0, dtype=np.uint64)\n",
    "    rows = tbl.column(\"row\").to_numpy()\n",
    "    cols = tbl.column(\"col\").to_numpy()\n",
    "    return _encode_keys(rows, cols)\n",
    "\n",
    "def write_panel_chunk(fire_id: str, frame: pd.DataFrame):\n",
    "    out_dir = OUT_ROOT / f\"fire_id={fire_id}\"\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    fn = out_dir / f\"part-{uuid.uuid4().hex[:8]}.parquet\"\n",
    "    pq.write_table(pa.Table.from_pandas(frame, preserve_index=False),\n",
    "                   fn, compression=\"zstd\", use_dbictionary=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce2eac9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import lru_cache\n",
    "from shapely import wkb as _wkb\n",
    "\n",
    "def build_panel_for_fire(fire_id: str, fire_year: int, geom_wkb: bytes, ref_tif_path: str):\n",
    "    \"\"\"Compute labels for a single fire polygon with lookback years, write Parquet parts.\"\"\"\n",
    "    # open grid inside worker\n",
    "    with rasterio.open(ref_tif_path) as src:\n",
    "        transform = src.transform\n",
    "        H, W = src.height, src.width\n",
    "\n",
    "        geom = _wkb.loads(geom_wkb)\n",
    "        if geom is None or geom.is_empty:\n",
    "            return (fire_id, 0, 0)\n",
    "\n",
    "        # buffer in projected meters\n",
    "        buffered = geom.buffer(BUFFER_METERS)\n",
    "\n",
    "        # pixel bbox\n",
    "        inv = ~transform\n",
    "        minx, miny, maxx, maxy = buffered.bounds\n",
    "        c0, r1 = inv * (minx, miny)\n",
    "        c1, r0 = inv * (maxx, maxy)\n",
    "        r0 = int(np.floor(max(0, min(r0, H - 1))))\n",
    "        r1 = int(np.floor(max(0, min(r1, H - 1))))\n",
    "        c0 = int(np.floor(max(0, min(c0, W - 1))))\n",
    "        c1 = int(np.floor(max(0, min(c1, W - 1))))\n",
    "\n",
    "        total_rows_written = 0\n",
    "        parts_written = 0\n",
    "        write_buffer = []  # list[pd.DataFrame]\n",
    "\n",
    "        @lru_cache(maxsize=10000)\n",
    "        def cached_event_keys(target_year: int, tile_i: int, tile_j: int) -> np.ndarray:\n",
    "            return load_event_keys_for_partition(EVENTS_ROOT, target_year, tile_i, tile_j)\n",
    "\n",
    "        for tile_i, tile_j in tiles_covering_bbox(r0, c0, r1, c1, TILE_SIZE):\n",
    "            win = window_from_tile(tile_i, tile_j, H, W, TILE_SIZE)\n",
    "            if win.width <= 0 or win.height <= 0:\n",
    "                continue\n",
    "\n",
    "            # rasterize buffered polygon into this tile\n",
    "            w_transform = rasterio.windows.transform(win, transform)\n",
    "            mask = rasterize(\n",
    "                [(mapping(buffered), 1)],\n",
    "                out_shape=(int(win.height), int(win.width)),\n",
    "                transform=w_transform,\n",
    "                fill=0, dtype=\"uint8\", all_touched=False,\n",
    "            )\n",
    "            if mask.max() == 0:\n",
    "                continue\n",
    "\n",
    "            rr, cc = np.nonzero(mask == 1)\n",
    "            if rr.size == 0:\n",
    "                continue\n",
    "\n",
    "            rows = rr + int(win.row_off)\n",
    "            cols = cc + int(win.col_off)\n",
    "            pixel_keys = _encode_keys(rows, cols)\n",
    "\n",
    "            base_cols = {\n",
    "                \"fire_id\": np.full(rows.size, fire_id),\n",
    "                \"row\": rows.astype(np.int32),\n",
    "                \"col\": cols.astype(np.int32),\n",
    "                \"tile_i\": np.full(rows.size, tile_i, dtype=np.int32),\n",
    "                \"tile_j\": np.full(rows.size, tile_j, dtype=np.int32),\n",
    "            }\n",
    "\n",
    "            # t in [fire_year - LOOKBACK_YEARS, fire_year - 1]\n",
    "            for t in range(fire_year - LOOKBACK_YEARS, fire_year):\n",
    "                ev_keys = cached_event_keys(t + 1, tile_i, tile_j)  # “treated next year”\n",
    "                treated = np.isin(pixel_keys, ev_keys, assume_unique=False).astype(np.int8)\n",
    "\n",
    "                frame = pd.DataFrame({\n",
    "                    **base_cols,\n",
    "                    \"year_t\": np.full(rows.size, t, dtype=np.int16),\n",
    "                    \"treated_next_year\": treated,\n",
    "                })\n",
    "                write_buffer.append(frame)\n",
    "                total_rows_written += frame.shape[0]\n",
    "\n",
    "                if total_rows_written >= WRITE_BUFFER_ROWS:\n",
    "                    write_panel_chunk(fire_id, pd.concat(write_buffer, ignore_index=True))\n",
    "                    write_buffer.clear()\n",
    "                    parts_written += 1\n",
    "\n",
    "        if write_buffer:\n",
    "            write_panel_chunk(fire_id, pd.concat(write_buffer, ignore_index=True))\n",
    "            parts_written += 1\n",
    "\n",
    "        return (fire_id, total_rows_written, parts_written)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0ce34b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sk77765/anaconda3/envs/torchgpu/lib/python3.10/site-packages/pyogrio/raw.py:198: RuntimeWarning: organizePolygons() received a polygon with more than 100 parts.  The processing may be really slow.  You can skip the processing by setting METHOD=SKIP.\n",
      "  return ogr_read(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fires=30730\n",
      "workers=12\n",
      "processed_fires: 30730\n",
      "rows_written: 21539339900\n",
      "parquet_parts: 197006\n"
     ]
    }
   ],
   "source": [
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "import geopandas as gpd, fiona\n",
    "import multiprocessing as mp\n",
    "\n",
    "# read fires once, project to raster CRS, and serialize geometry to WKB\n",
    "ref_tif = find_reference_tif(DIST_ROOT)\n",
    "with open_grid(ref_tif) as src:\n",
    "    raster_crs = src.crs\n",
    "\n",
    "layers = fiona.listlayers(FIRE_GDB.as_posix())\n",
    "layer_name = next((L for L in layers if \"BURN\" in L.upper() and \"BOUND\" in L.upper()), layers[0])\n",
    "\n",
    "fires_gdf = gpd.read_file(FIRE_GDB.as_posix(), layer=layer_name).to_crs(raster_crs)\n",
    "geom_col = fires_gdf.geometry.name\n",
    "cols_upper = {c.upper(): c for c in fires_gdf.columns}\n",
    "year_col = next(c for k in (\"YEAR\",\"FIRE_YEAR\",\"YR\") if (c := cols_upper.get(k)))\n",
    "id_col   = next(c for k in (\"FIRE_ID\",\"IRWINID\",\"MAP_ID\",\"OBJECTID\") if (c := cols_upper.get(k)))\n",
    "\n",
    "fires_gdf = fires_gdf[fires_gdf[geom_col].notnull()].copy()\n",
    "fires_gdf[\"FIRE_ID\"] = fires_gdf[id_col].astype(str)\n",
    "fires_gdf[\"YEAR\"]    = fires_gdf[year_col].astype(int)\n",
    "fires_gdf[\"GEOM_WKB\"] = fires_gdf.geometry.to_wkb()\n",
    "\n",
    "fire_records = list(fires_gdf[[\"FIRE_ID\",\"YEAR\",\"GEOM_WKB\"]].itertuples(index=False, name=None))\n",
    "print(f\"fires={len(fire_records)}\")\n",
    "\n",
    "# parallel CPU using fork (works in notebooks)\n",
    "ctx = mp.get_context(\"fork\")\n",
    "WORKERS = max(1, min(12, (os.cpu_count() or 8) - 4))\n",
    "print(f\"workers={WORKERS}\")\n",
    "\n",
    "stats = []\n",
    "with ProcessPoolExecutor(max_workers=WORKERS, mp_context=ctx) as ex:\n",
    "    futs = {\n",
    "        ex.submit(build_panel_for_fire, fid, yr, wkb, str(ref_tif)): fid\n",
    "        for (fid, yr, wkb) in fire_records\n",
    "    }\n",
    "    for f in as_completed(futs):\n",
    "        fid = futs[f]\n",
    "        try:\n",
    "            stats.append(f.result())\n",
    "        except Exception as e:\n",
    "            print(\"fail:\", fid, e)\n",
    "\n",
    "print(\"processed_fires:\", len(stats))\n",
    "print(\"rows_written:\", sum(r for _, r, _ in stats))\n",
    "print(\"parquet_parts:\", sum(p for _, _, p in stats))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21c188d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchgpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
